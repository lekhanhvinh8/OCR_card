{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the EAST model and Load it\n",
    "model = cv2.dnn.readNet('frozen_east_text_detection.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688 1102\n",
      "672 1088\n"
     ]
    }
   ],
   "source": [
    "# ## Prepare the image\n",
    "img = cv2.imread('bank_card.png')\n",
    "\n",
    "# use multiple of 32 to set the new img shape\n",
    "height, width, _ = img.shape\n",
    "print(height, width)\n",
    "\n",
    "new_height = (height//32)*32\n",
    "new_width = (width//32)*32\n",
    "print(new_height, new_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0238095238095237 1.0128676470588236\n"
     ]
    }
   ],
   "source": [
    "# get the ratio change in width and height\n",
    "h_ratio = height/new_height\n",
    "w_ratio = width/new_width\n",
    "print(h_ratio, w_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(img, 1, (new_width, new_height),(123.68, 116.78, 103.94), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Pass the image to network and extract score and geometry map\n",
    "model.setInput(blob)\n",
    "\n",
    "model.getUnconnectedOutLayersNames()\n",
    "\n",
    "(geometry, scores) = model.forward(model.getUnconnectedOutLayersNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Post-Processing\n",
    "\n",
    "rectangles = []\n",
    "confidence_score = []\n",
    "for i in range(geometry.shape[2]):\n",
    "    for j in range(0, geometry.shape[3]):\n",
    "        \n",
    "        if scores[0][0][i][j] < 0.1:\n",
    "            continue\n",
    "            \n",
    "        bottom_x = int(j*4 + geometry[0][1][i][j])\n",
    "        bottom_y = int(i*4 + geometry[0][2][i][j])\n",
    "        \n",
    "\n",
    "        top_x = int(j*4 - geometry[0][3][i][j])\n",
    "        top_y = int(i*4 - geometry[0][0][i][j])\n",
    "        \n",
    "        rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "        confidence_score.append(float(scores[0][0][i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Non-max suppression to get the required rectangles\n",
    "fin_boxes = non_max_suppression(np.array(rectangles), probs=confidence_score, overlapThresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_copy = img.copy()\n",
    "\n",
    "for (x1, y1, x2, y2) in fin_boxes:\n",
    "\n",
    "    x1 = int(x1 * w_ratio)\n",
    "    y1 = int(y1 * h_ratio)\n",
    "    x2 = int(x2 * w_ratio)\n",
    "    y2 = int(y2 * h_ratio)\n",
    "    \n",
    "    cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow(\"Text Detection\", img_copy)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[907, 463, 1042, 488], [678, 460, 749, 479], [97, 567, 377, 605], [924, 557, 1022, 593], [99, 485, 211, 528], [738, 460, 791, 479], [465, 396, 608, 443], [282, 396, 423, 442], [679, 484, 801, 527], [92, 395, 240, 443], [776, 72, 1004, 134], [652, 396, 794, 441], [446, 71, 749, 133], [593, 487, 651, 514], [596, 500, 655, 528]]\n"
     ]
    }
   ],
   "source": [
    "fin_boxes = [[int(x1*w_ratio), int(y1 * h_ratio), int(x2 * w_ratio), int(y2 * h_ratio)] for x1, y1, x2, y2 in fin_boxes]\n",
    "\n",
    "print(fin_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(image, fin_boxes):\n",
    "    crop_imgs = []\n",
    "\n",
    "    for boundingbox in fin_boxes:\n",
    "\n",
    "        x1 = boundingbox[0]\n",
    "        y1 = boundingbox[1]\n",
    "        x2 = boundingbox[2]\n",
    "        y2 = boundingbox[3]\n",
    "\n",
    "        crop_img = img[y1:y2, x1:x2]\n",
    "\n",
    "        crop_imgs.append(crop_img)\n",
    "        \n",
    "    return crop_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, name=None):\n",
    "\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crnn():\n",
    "    \n",
    "    # input with shape of height=32 and width=128 \n",
    "    inputs = Input(shape=(32, 128, 1), name=\"image\")\n",
    "\n",
    "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "    conv_1 = Conv2D(32, (3,3), activation = \"selu\", padding='same')(inputs)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2))(conv_1)\n",
    "    \n",
    "    conv_2 = Conv2D(64, (3,3), activation = \"selu\", padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2))(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(pool_2)\n",
    "    conv_4 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(conv_3)\n",
    "\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    "    \n",
    "    conv_5 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(pool_4)\n",
    "    \n",
    "    # Batch normalization layer\n",
    "    batch_norm_5 = BatchNormalization()(conv_5)\n",
    "    \n",
    "    conv_6 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(batch_norm_5)\n",
    "    batch_norm_6 = BatchNormalization()(conv_6)\n",
    "    pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "    \n",
    "    conv_7 = Conv2D(64, (2,2), activation = \"selu\")(pool_6)\n",
    "    \n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "    \n",
    "    # bidirectional LSTM layers with units=128\n",
    "    blstm_1 = Bidirectional(LSTM(128, return_sequences=True))(squeezed)\n",
    "    blstm_2 = Bidirectional(LSTM(128, return_sequences=True))(blstm_1)\n",
    "\n",
    "    softmax_output = Dense(len(char_list) + 1, activation = 'softmax', name=\"dense\")(blstm_2)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, softmax_output) #y_true = labels, y_pred = softmax_output\n",
    "\n",
    "    #model to be used at training time\n",
    "    model = Model(inputs=[inputs, labels], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_crnn()\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model.compile(optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('C_LSTM_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction model by extracting layers till the output layer\n",
    "prediction_model = keras.models.Model(\n",
    "    model.input[0], model.get_layer(name=\"dense\").output #model.input[0] corresponses model.get_layer(name=\"inage\").input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def ctc_decoder(predictions):\n",
    "    '''\n",
    "    input: given batch of predictions from text rec model\n",
    "    output: return lists of raw extracted text\n",
    "\n",
    "    '''\n",
    "    text_list = []\n",
    "    \n",
    "    pred_indcies = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    for i in range(pred_indcies.shape[0]):\n",
    "        ans = \"\"\n",
    "        \n",
    "        ## merge repeats\n",
    "        merged_list = [k for k,_ in groupby(pred_indcies[i])]\n",
    "        \n",
    "        ## remove blanks\n",
    "        for p in merged_list:\n",
    "            if p != len(char_list): # len(char_list) = 62, which is a number that be pass as a padding of labels\n",
    "                ans += char_list[int(p)]\n",
    "        \n",
    "        text_list.append(ans)\n",
    "        \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mastercad'], ['MMONTHD'], ['CARDHOLDER'], ['WISA'], ['gADD'], ['YYEAR'], ['PBnG'], ['Bdgla'], ['MIsO'], ['Pebs'], ['CARID'], ['IduE'], ['CRIEDIT'], ['VALID'], ['Tupt']]\n"
     ]
    }
   ],
   "source": [
    "final_texts = []\n",
    "\n",
    "for crop_img in crop_images(img_copy, fin_boxes):\n",
    "\n",
    "    test_image = cv2.cvtColor(crop_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    test_image = cv2.resize(test_image, (128, 32))\n",
    "\n",
    "    #cv2.imshow(\"image\", test_image)\n",
    "    #cv2.waitKey(0)\n",
    "\n",
    "    test_image = test_image / 255\n",
    "\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "    test_image = test_image.reshape([32, 128, 1])\n",
    "\n",
    "    test_image = test_image[np.newaxis]\n",
    "    \n",
    "    preds = prediction_model.predict(test_image)\n",
    "    pred_texts = ctc_decoder(preds)\n",
    "\n",
    "    final_texts.append(pred_texts)\n",
    "\n",
    "print(final_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, len(final_texts)):\n",
    "    cv2.putText(img_copy, \n",
    "                final_texts[i][0], \n",
    "                (fin_boxes[i][0] - 10, fin_boxes[i][1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1.2, \n",
    "                (0, 255, 0), \n",
    "                2)\n",
    "\n",
    "cv2.imshow(\"Image\", img_copy)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
