{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSdC-DdnAV55"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-l6JCqxQYiDJ"
   },
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "image_texts = []\n",
    "\n",
    "data_folder = \"mjsynth_sample\"\n",
    "\n",
    "for path in os.listdir(data_folder):\n",
    "    image_paths.append(data_folder + \"/\" + path)\n",
    "    image_texts.append(path.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zU_i-crjAV6P",
    "outputId": "3f7ff0ba-c304-4781-d9ba-7f2c0fed9b61"
   },
   "outputs": [],
   "source": [
    "### get vocabulary for the current dataset\n",
    "vocab = set(\"\".join(map(str, image_texts)))\n",
    "char_list = sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "-7PMuKJ0AV6j",
    "outputId": "ef37733a-7c37-4f65-e153-ab576bfdce3a"
   },
   "outputs": [],
   "source": [
    "max_label_len = max([len(str(text)) for text in image_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(max_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrT_x2Qt3GgH"
   },
   "outputs": [],
   "source": [
    "def encode_to_labels(txt):\n",
    "    # encoding each output word into digits\n",
    "    dig_lst = []\n",
    "    \n",
    "    for index, char in enumerate(txt):\n",
    "        try:\n",
    "            dig_lst.append(char_list.index(char))\n",
    "        except:\n",
    "            print(char)\n",
    "    \n",
    "    return pad_sequences([dig_lst], maxlen=max_label_len, padding='post', value=len(char_list))[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "GZS66fcx_BPn",
    "outputId": "c6fe5a17-e652-44b9-df9e-25df41c3e4ac"
   },
   "outputs": [],
   "source": [
    "padded_image_texts = list(map(encode_to_labels, image_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEbgSpZiAV6e"
   },
   "outputs": [],
   "source": [
    "train_image_paths = image_paths[ : int(len(image_paths) * 0.90)]\n",
    "train_image_texts = padded_image_texts[ : int(len(image_texts) * 0.90)]\n",
    "\n",
    "val_image_paths = image_paths[int(len(image_paths) * 0.90) : ]\n",
    "val_image_texts = padded_image_texts[int(len(image_texts) * 0.90) : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFUMV5sV7vVf"
   },
   "outputs": [],
   "source": [
    "def process_single_sample(img_path, label):\n",
    "\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "\n",
    "    #img2 = cv2.imread() corresponding img2 = tf.io.read_file() and img2 = tf.io.decode_png(img2, channels=3)\n",
    "    \n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img, [32, 128])\n",
    "\n",
    "    return {\"image\": img, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UlVa4gJ7uck"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_image_texts))\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_image_paths, val_image_texts))\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(\n",
    "        process_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "Fe5lqjgCk7sY",
    "outputId": "9331d749-e975-4524-9d3e-925195905d70"
   },
   "outputs": [],
   "source": [
    "# Mapping characters to integers\n",
    "char_to_num = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=char_list, num_oov_indices=0, mask_token=None\n",
    ")\n",
    "\n",
    "# Mapping integers back to original character\n",
    "num_to_char = layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeN-LJBoAV6u"
   },
   "outputs": [],
   "source": [
    "## Ref: https://keras.io/examples/vision/captcha_ocr/\n",
    "\n",
    "class CTCLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, name=None):\n",
    "\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsyoyxwgZmcD"
   },
   "outputs": [],
   "source": [
    "def ctc_decoder(predictions):\n",
    "    '''\n",
    "    input: given batch of predictions from text rec model\n",
    "    output: return lists of raw extracted text\n",
    "\n",
    "    '''\n",
    "    text_list = []\n",
    "    \n",
    "    pred_indcies = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    for i in range(pred_indcies.shape[0]):\n",
    "        ans = \"\"\n",
    "        \n",
    "        ## merge repeats\n",
    "        merged_list = [k for k,_ in groupby(pred_indcies[i])]\n",
    "        \n",
    "        ## remove blanks\n",
    "        for p in merged_list:\n",
    "            if p != len(char_list):\n",
    "                ans += char_list[int(p)]\n",
    "        \n",
    "        text_list.append(ans)\n",
    "        \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81cSDEPihQwx"
   },
   "outputs": [],
   "source": [
    "def create_crnn():\n",
    "    \n",
    "    # input with shape of height=32 and width=128 \n",
    "    inputs = Input(shape=(32, 128, 1), name=\"image\")\n",
    "\n",
    "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "    conv_1 = Conv2D(32, (3,3), activation = \"selu\", padding='same')(inputs)\n",
    "    pool_1 = MaxPool2D(pool_size=(2, 2))(conv_1)\n",
    "    \n",
    "    conv_2 = Conv2D(64, (3,3), activation = \"selu\", padding='same')(pool_1)\n",
    "    pool_2 = MaxPool2D(pool_size=(2, 2))(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(pool_2)\n",
    "    conv_4 = Conv2D(128, (3,3), activation = \"selu\", padding='same')(conv_3)\n",
    "\n",
    "    pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    "    \n",
    "    conv_5 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(pool_4)\n",
    "    \n",
    "    # Batch normalization layer\n",
    "    batch_norm_5 = BatchNormalization()(conv_5)\n",
    "    \n",
    "    conv_6 = Conv2D(256, (3,3), activation = \"selu\", padding='same')(batch_norm_5)\n",
    "    batch_norm_6 = BatchNormalization()(conv_6)\n",
    "    pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "    \n",
    "    conv_7 = Conv2D(64, (2,2), activation = \"selu\")(pool_6)\n",
    "    \n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
    "    \n",
    "    # bidirectional LSTM layers with units=128\n",
    "    blstm_1 = Bidirectional(LSTM(128, return_sequences=True))(squeezed)\n",
    "    blstm_2 = Bidirectional(LSTM(128, return_sequences=True))(blstm_1)\n",
    "\n",
    "    softmax_output = Dense(len(char_list) + 1, activation = 'softmax', name=\"dense\")(blstm_2)\n",
    "\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, softmax_output) #y_true = labels, y_pred = softmax_output\n",
    "\n",
    "    #model to be used at training time\n",
    "    model = Model(inputs=[inputs, labels], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T_sCV7kUhTxC",
    "outputId": "cd20a4bf-2146-4e02-866b-fc01d998f316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image (InputLayer)              [(None, 32, 128, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 128, 32)  320         image[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 64, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 64, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 32, 64)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 8, 32, 128)   73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 32, 128)   147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 32, 128)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 32, 256)   295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4, 32, 256)   1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 4, 32, 256)   590080      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4, 32, 256)   1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 32, 256)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 1, 31, 64)    65600       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 31, 64)       0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 31, 256)      197632      lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 31, 256)      394240      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "label (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 31, 63)       16191       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss (CTCLayer)             (None, 31, 63)       0           label[0][0]                      \n",
      "                                                                 dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,801,215\n",
      "Trainable params: 1,800,191\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_crnn()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model.compile(optimizer = optimizer)\n",
    "\n",
    "file_path = \"C_LSTM_best1.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=file_path, \n",
    "                            monitor='val_loss', \n",
    "                            verbose=1, \n",
    "                            save_best_only=True, \n",
    "                            mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint, \n",
    "                  EarlyStopping(patience=3, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, \n",
    "                        epochs = 30,\n",
    "                        validation_data=validation_dataset,\n",
    "                        verbose = 1,\n",
    "                        callbacks = callbacks_list,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2f72vfOaHAF"
   },
   "outputs": [],
   "source": [
    "model.load_weights('C_LSTM_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 31, 63) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(name=\"dense\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "colab_type": "code",
    "id": "JT3udqmt8JpX",
    "outputId": "6b91d57d-d2bb-4b12-825e-532edf285d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 32, 128, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 128, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 32, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 32, 128)        73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 32, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 32, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 32, 256)        1024      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 32, 256)        590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 32, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 32, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 31, 64)         65600     \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 31, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 31, 256)           197632    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 31, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 31, 63)            16191     \n",
      "=================================================================\n",
      "Total params: 1,801,215\n",
      "Trainable params: 1,800,191\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the prediction model by extracting layers till the output layer\n",
    "prediction_model = keras.models.Model(\n",
    "    model.input[0], model.get_layer(name=\"dense\").output #model.input[0] corresponses model.get_layer(name=\"inage\").input\n",
    ")\n",
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2o-Go-9Xi6u"
   },
   "outputs": [],
   "source": [
    "test_image = cv2.imread(\"credit_card.png\")\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "test_image = cv2.resize(test_image, (128, 32))\n",
    "\n",
    "cv2.imshow(\"image\", test_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "test_image = test_image / 255\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "test_image = test_image.reshape([32, 128, 1])\n",
    "\n",
    "test_image = test_image[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CREDITCARD']\n"
     ]
    }
   ],
   "source": [
    "preds = prediction_model.predict(test_image)\n",
    "pred_texts = ctc_decoder(preds)\n",
    "print(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[9.0820930e-07 5.6513776e-09 1.2383899e-07 ... 8.7395343e-08\n",
      "   1.7204249e-07 6.1065897e-05]\n",
      "  [1.1961998e-07 5.4290901e-09 1.6112102e-08 ... 2.8037553e-08\n",
      "   2.9852409e-09 9.9166155e-01]\n",
      "  [4.1305523e-09 4.3449941e-09 3.3888328e-09 ... 1.4585847e-08\n",
      "   3.0949904e-10 9.9997580e-01]\n",
      "  ...\n",
      "  [3.9084491e-09 3.1678280e-09 3.8347156e-10 ... 4.2657183e-11\n",
      "   1.6613957e-10 9.9998033e-01]\n",
      "  [2.2875629e-07 5.9499676e-08 1.1205553e-08 ... 1.5436293e-09\n",
      "   5.1021911e-09 9.9690896e-01]\n",
      "  [1.8435275e-06 2.7236644e-09 3.9523425e-08 ... 3.2539202e-07\n",
      "   1.1442454e-08 1.2383174e-08]]]\n",
      "[[12 62 62 62 27 62 62 14 62 62 13 62 18 18 62 29 62 62 62 12 62 62 10 62\n",
      "  62 62 27 62 62 62 13]]\n"
     ]
    }
   ],
   "source": [
    "text_list = []\n",
    "\n",
    "print(preds)\n",
    "\n",
    "pred_indcies = np.argmax(preds, axis=2)\n",
    "\n",
    "print(pred_indcies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(preds[0])) # max len of word ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 62 62 62 27 62 62 14 62 62 13 62 18 18 62 29 62 62 62 12 62 62 10 62\n",
      "  62 62 27 62 62 62 13]]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(preds, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 62, 27, 62, 14, 62, 13, 62, 18, 62, 29, 62, 12, 62, 10, 62, 27, 62, 13]\n"
     ]
    }
   ],
   "source": [
    "print([k for k,_ in groupby(pred_indcies[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = \"\"\n",
    "\n",
    "## merge repeats\n",
    "merged_list = [k for k,_ in groupby(pred_indcies[0])]\n",
    "\n",
    "## remove blanks\n",
    "for p in merged_list:\n",
    "    if p != len(char_list):\n",
    "        ans += char_list[int(p)]\n",
    "\n",
    "text_list.append(ans)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CRNN_CTC_wandb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
